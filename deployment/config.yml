---
app:
  # The name of the application
  name: howsami

  # The hostname for the ingress endpoint.
  host: howsami.local

cluster:
  # The kubernetes namespace to deploy to
  namespace: howsami

docker:
  # Registry / account to push the images to
  #  <registry>/<image name>:<tag>
  registry: "ghcr.io/watcherwhale"

  imagePullSecrets:
    - name: ghcr-io

  # The docker pull poliicy
  # - Never
  # - Always
  # - IfNotPresent
  pullPolicy: IfNotPresent

redis:
  # Run all instances on speperate hosts
  hostSeperated: true

  # Docker tag of the redis pods
  tag: 6-alpine

  # Amount of redis database replicas
  # Must be at least 3
  replicas: 3

sequencer:
  # The log level of this service
  #   - error
  #   - warn
  #   - info
  #   - http (http access logs)
  #   - verbose
  #   - debug
  #   - silly
  loglevel: http

  # Amount of sequencer minimum and maximum replicas.
  replicas:
    min: 1
    max: 10

  # The docker tag to pull
  tag: latest

# All checklists to deploy (and/or build) to the cluster.
#   Name is the name of the image
checklists:

  - name: dns

    # The docker image tag: <name>-<tag>
    tag: latest

    # Amount of jobs one instance can handle
    #  in the specified interval.
    throughput: 20

    # The interval (miliseconds) to periodicaly check
    #  the size of the queue, and down/up scale
    interval: 10000

    # Amount of time (seconds) to stabilize downscaling.
    stabilization: 200

    # Define the range of amount of replicas to deploy.
    replicas:
      min: 1
      max: 5
      
  - name: mail

    # The docker image tag: <name>-<tag>
    tag: latest

    # Amount of jobs one instance can handle
    #  in the specified interval.
    throughput: 20

    # The interval (miliseconds) to periodicaly check
    #  the size of the queue, and down/up scale
    interval: 10000

    # Amount of time (seconds) to stabilize downscaling.
    stabilization: 200

    # Define the range of amount of replicas to deploy.
    replicas:
      min: 1
      max: 5

  - name: https

    # The docker image tag: <name>-<tag>
    tag: latest

    # Amount of jobs one instance can handle
    #  in the specified interval.
    throughput: 20

    # The interval (miliseconds) to periodicaly check
    #  the size of the queue, and down/up scale
    interval: 10000

    # The interval (miliseconds) to periodicaly check
    #  the size of the queue, and down/up scale
    stabilization: 200

    # Define the range of amount of replicas to deploy.
    replicas:
      min: 1
      max: 5

  - name: ip

    # The docker image tag: <name>-<tag>
    tag: latest

    # Amount of jobs one instance can handle
    #  in the specified interval.
    throughput: 20

    # The interval (miliseconds) to periodicaly check
    #  the size of the queue, and down/up scale
    interval: 10000

    # The interval (miliseconds) to periodicaly check
    #  the size of the queue, and down/up scale
    stabilization: 200

    # Define the range of amount of replicas to deploy.
    replicas:
      min: 1
      max: 5


# Logging
fluentd:
  # Deploy fluentd
  enabled: true

  # Namespace where fluentd lives
  namespace: fluentd

  # Docker Image
  #   Best practice is to create a custom fluentd dockerfile
  #   with preinstalled plugins of choice.
  image: fluent/fluentd-kubernetes-daemonset
  tag: v1-debian-elasticsearch

  # Elasticsearch
  #   Additional settings can be configured in:
  #     ./fluentd/fluentd-config/elastic.conf
  elastic:
    enabled: false

    # Connection details
    host: elasticsearch
    port: 9200

  # Custom fluentd config file
  #   Add additional custom fluentd config options to the instance:
  #     ./fluentd/fluentd-config/custom.conf
  custom:
    enabled: false

autoscaler:
  enabled: true

  # https://github.com/jthomperoo/custom-pod-autoscaler-operator/releases
  version: v1.2.0

build:
  # Build all images before deploying
  enabled: true

  # The tags for building
  #  <registry>/<image name>:<tag>
  tags:
    - latest
    - dev

  # Push to registry
  push: yes
